#!/usr/bin/env bash
set -euo pipefail

############################################################
# ITCS-6190 COURSE PROJECT â€” MASTER PIPELINE (run.sh)
# Runs the entire offline pipeline with ONE command:
#
#   1. Ingest raw â†’ curated
#   2. Extended EDA (tables + plots)
#   3. Spark SQL analysis
#   4. ML model training (PipelineModel)
#   5. Create streaming micro-batches
#
# Streaming + prediction demo is run separately using:
#   ./run_stream_predict.sh
############################################################

log(){ printf "\n[%s] %s\n" "$(date +'%H:%M:%S')" "$*"; }

###############################
# ENVIRONMENT
###############################
[ -d ".venv" ] && source .venv/bin/activate || true
[ -f ".env" ] && export $(grep -v '^#' .env | xargs) || true

export RAW_DATA_GLOB="./data/raw/**/*.csv"
export CURATED_DIR="./outputs/curated"
export TABLE_DIR="./outputs/tables"
export PLOTS_DIR="./outputs/plots"
export STREAM_DIR="./data/stream"

mkdir -p "$CURATED_DIR" "$TABLE_DIR" "$PLOTS_DIR" "$STREAM_DIR"

###############################
# JAVA for Spark
###############################
if ! command -v java >/dev/null 2>&1; then
  log "Installing OpenJDK 17â€¦"
  sudo apt-get update -y
  sudo apt-get install -y openjdk-17-jdk
fi
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
export PATH="$JAVA_HOME/bin:$PATH"

###############################
# PYTHON DEPENDENCIES
###############################
log "Installing Python dependenciesâ€¦"
pip install --upgrade pip
pip install -r requirements.txt || pip install pyspark pandas matplotlib pyarrow python-dotenv

################################
# STEP 1 â€” INGEST (ONLY IF RAW CSVs EXIST)
################################
echo "[1/5] Checking for raw CSVs in data/raw/ ..."

if ls data/raw/*.csv data/raw/**/*.csv 1>/dev/null 2>&1; then
    echo "[1/5] Raw CSVs found â€” running ingestion."
    python src/01_ingest_eda.py
else
    echo "[1/5] No raw CSV files found in data/raw/ â€” skipping ingestion and using existing curated data."
fi



###############################
# STEP 2 â€” EXTENDED EDA
###############################
if [ -f "src/02_extended_eda.py" ]; then
  log "STEP 2 â€” Extended EDA (tables + plots)"
  python src/02_extended_eda.py \
    --curated_dir "$CURATED_DIR" \
    --plots_dir "$PLOTS_DIR" \
    --sample_for_plots 250000
  log "âœ“ EDA tables â†’ outputs/tables/ | Plots â†’ outputs/plots/"
else
  log "âš  SKIP: src/02_extended_eda.py not found"
fi

###############################
# STEP 3 â€” SPARK SQL ANALYSIS
###############################
if [ -f "src/02_sql_analysis.py" ]; then
  log "STEP 3 â€” Spark SQL analysis"
  python src/02_sql_analysis.py
  log "âœ“ SQL output tables â†’ outputs/tables/"
else
  log "âš  WARNING: src/02_sql_analysis.py missing â€” SQL requirement not satisfied"
fi

###############################
# STEP 4 â€” ML MODEL TRAINING
###############################
log "STEP 4 â€” Train ML model"
python src/03_predictive_model.py \
  --task classify \
  --algo lr \
  --curated_dir "$CURATED_DIR" \
  --models_dir "./outputs/models"
log "âœ“ Model saved â†’ outputs/models/"

###############################
# STEP 5 â€” CREATE STREAM BATCHES
###############################
log "STEP 5 â€” Create streaming micro-batches"
python src/04a_make_stream_batches.py \
  --curated_dir "$CURATED_DIR" \
  --stream_dir "$STREAM_DIR"
log "âœ“ Streaming batches â†’ data/stream/"

###############################
# DONE
###############################
log "ðŸŽ‰ Pipeline COMPLETED successfully!"
echo "
=========================================================
 EVERYTHING IS READY:

  â€¢ Curated data:        outputs/curated/
  â€¢ EDA tables:          outputs/tables/
  â€¢ EDA plots:           outputs/plots/
  â€¢ SQL analysis:        outputs/tables/
  â€¢ Trained model:       outputs/models/
  â€¢ Streaming batches:   data/stream/

To run online streaming predictions + ML scoring:
    ./run_stream_predict.sh

To view streaming predictions PNG dashboard:
    python src/viz_stream_live.py
=========================================================
"